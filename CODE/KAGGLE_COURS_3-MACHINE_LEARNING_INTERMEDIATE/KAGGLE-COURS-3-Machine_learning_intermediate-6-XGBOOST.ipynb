{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. INTERMEDIATE MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6. XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  astuce pour afficher toutes les lignes sans les ...\n",
    "pd.set_option('display.max_row', 80)\n",
    "#  astuce pour afficher toutes les colonnes dans les head()\n",
    "pd.set_option('display.max_column', 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHARGEMENT DES DATASETS FULL ET TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des datasets\n",
    "dataset_input_path = 'C:/Users/PC Maison/4-KAGGLE\\KAGGLE_DEV/KAGGLE_COURS_3-MACHINE_LEARNING_INTERMEDIATE/'\n",
    "X = pd.read_csv(dataset_input_path + 'home-data-for-ml-course/input/train.csv', index_col='Id')\n",
    "X_test_full = pd.read_csv(dataset_input_path + 'home-data-for-ml-course/input/test.csv', index_col='Id')# Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TARGET ET FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing target, separate target from predictors\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice              \n",
    "X.drop(['SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN SET et VAL SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, \n",
    "                                                                train_size=0.8, \n",
    "                                                                test_size=0.2,\n",
    "                                                                random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NUMERIQUES / CATEGORICAL FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality\n",
    "# (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = low_cardinality_cols + numeric_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()\n",
    "\n",
    "# One-hot encode the data (to shorten the code, we use pandas)\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_valid = pd.get_dummies(X_valid)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "X_train, X_valid = X_train.align(X_valid, join='left', axis=1)\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETAPE 1 - BUILD MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostLibraryNotFound",
     "evalue": "Cannot find XGBoost Library in the candidate path, did you install compilers and run build.sh in root path?\nList of candidates:\nC:\\Users\\Outils\\lib\\site-packages\\xgboost\\xgboost.dll\nC:\\Users\\Outils\\lib\\site-packages\\xgboost\\../../lib/xgboost.dll\nC:\\Users\\Outils\\lib\\site-packages\\xgboost\\./lib/xgboost.dll\nC:\\Users\\Outils\\xgboost\\xgboost.dll\nC:\\Users\\Outils\\lib\\site-packages\\xgboost\\../../windows/x64/Release/xgboost.dll\nC:\\Users\\Outils\\lib\\site-packages\\xgboost\\./windows/x64/Release/xgboost.dll",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostLibraryNotFound\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-69cb7f7869e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Define the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmy_model_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Outils\\lib\\site-packages\\xgboost\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrabit\u001b[0m                   \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Outils\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;31m# load the XGBoost library globally\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m \u001b[0m_LIB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Outils\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_load_lib\u001b[1;34m()\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;34m\"\"\"Load xgboost Library.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[0mlib_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_lib_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlib_paths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Outils\\lib\\site-packages\\xgboost\\libpath.py\u001b[0m in \u001b[0;36mfind_lib_path\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m# From github issues, most of installation errors come from machines w/o compilers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlib_path\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'XGBOOST_BUILD_DOC'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         raise XGBoostLibraryNotFound(\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[1;34m'Cannot find XGBoost Library in the candidate path, '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;34m'did you install compilers and run build.sh in root path?\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostLibraryNotFound\u001b[0m: Cannot find XGBoost Library in the candidate path, did you install compilers and run build.sh in root path?\nList of candidates:\nC:\\Users\\Outils\\lib\\site-packages\\xgboost\\xgboost.dll\nC:\\Users\\Outils\\lib\\site-packages\\xgboost\\../../lib/xgboost.dll\nC:\\Users\\Outils\\lib\\site-packages\\xgboost\\./lib/xgboost.dll\nC:\\Users\\Outils\\xgboost\\xgboost.dll\nC:\\Users\\Outils\\lib\\site-packages\\xgboost\\../../windows/x64/Release/xgboost.dll\nC:\\Users\\Outils\\lib\\site-packages\\xgboost\\./windows/x64/Release/xgboost.dll"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define the model\n",
    "my_model_1 = XGBRegressor(random_state=0)\n",
    "\n",
    "# Fit the model\n",
    "my_model_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Get predictions\n",
    "predictions_1 = my_model_1.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MAE\n",
    "mae_1 = mean_absolute_error(y_valid, predictions_1)\n",
    "\n",
    "# Uncomment to print MAE\n",
    "print(\"Mean Absolute Error:\" , mae_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETAPE 2 - IMPROVE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "my_model_2 = XGBRegressor(n_estimators=1000, learning_rate='0.05')\n",
    "\n",
    "# Fit the model\n",
    "my_model_2.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions\n",
    "predictions_2 = my_model_2.predict(X_valid)\n",
    "\n",
    "# Calculate MAE\n",
    "mae_2 = mean_absolute_error(y_valid, predictions_2)\n",
    "\n",
    "# Uncomment to print MAE\n",
    "print(\"Mean Absolute Error:\" , mae_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE : 17213.82253317637  - n_etimators=1000 learning_rate=0.05\n",
    "# MAE : 16913.731043985445 - n_etimators=1000 learning_rate=0.01\n",
    "# MAE : 16897.355856699487 - n_etimators=2000 learning_rate=0.01\n",
    "# MAE : 29301.916938677226 - n_etimators=2000 learning_rate=0.001 overfit\n",
    "# MAE : 16846.77787885274  - n_etimators=2000 learning_rate=0.05\n",
    "# MAE : 17936.201599957192 - n_etimators=2000 learning_rate=0.002\n",
    "# MAE : 17124.38484589041  - n_etimators=2000 learning_rate=0.04\n",
    "# MAE : 16682.16697880993  - n_etimators=3000 learning_rate=0.05\n",
    "# MAE : 16682.069750642124 - n_etimators=4000 learning_rate=0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETAPE 3 : BREAK THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "my_model_3 = XGBRegressor(n_estimators=4000, learning_rate='0.05')\n",
    "\n",
    "# Fit the model\n",
    "my_model_3.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions\n",
    "predictions_3 = my_model_3.predict(X_valid)\n",
    "\n",
    "# Calculate MAE\n",
    "mae_3 = mean_absolute_error(y_valid, predictions_3)\n",
    "\n",
    "# Uncomment to print MAE\n",
    "print(\"Mean Absolute Error:\" , mae_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Absolute Error: 127895.0828807256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
