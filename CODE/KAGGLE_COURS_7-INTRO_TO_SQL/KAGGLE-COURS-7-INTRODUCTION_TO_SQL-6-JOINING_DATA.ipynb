{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. INTRODUCTION TO SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.6. JOINING DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.6.1. COURS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6.1.1. JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupérer des infos de plusieurs tables\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT p.Name AS Pet_Name, o.Name AS Owner_Name\n",
    "        FROM 'bigquery-public-data.pet_records.pets' AS p\n",
    "        INNER JOIN 'bigquery-public-data.pet_records.owners' AS o\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  exemple :\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT L.license, COUNT(1) AS number_of_files\n",
    "        FROM `bigquery-public-data.github_repos.sample_files` AS sf\n",
    "        INNER JOIN `bigquery-public-data.github_repos.licenses` AS L \n",
    "            ON sf.repo_name = L.repo_name\n",
    "        GROUP BY L.license\n",
    "        ORDER BY number_of_files DESC\n",
    "        \"\"\"\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 10 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "query_job = client.query(query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and convert the results to a pandas DataFrame\n",
    "file_count_by_license = query_job.to_dataframe()\n",
    "\n",
    "# Print the DataFrame\n",
    "file_count_by_license\n",
    "\n",
    "# \tlicense\tnumber_of_files\n",
    "# 0\tmit\t20432437\n",
    "# 1\tgpl-2.0\t16866825\n",
    "# 2\tapache-2.0\t7114007\n",
    "# 3\tgpl-3.0\t4936479\n",
    "# 4\tbsd-3-clause\t2926576\n",
    "# 5\tagpl-3.0\t1293773\n",
    "# 6\tlgpl-2.1\t793054\n",
    "# 7\tbsd-2-clause\t694767\n",
    "# 8\tlgpl-3.0\t564433\n",
    "# 9\tmpl-2.0\t473078\n",
    "# 10\tcc0-1.0\t405925\n",
    "# 11\tepl-1.0\t320203\n",
    "# 12\tunlicense\t208912\n",
    "# 13\tartistic-2.0\t148414\n",
    "# 14\tisc\t117709"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.6.2. EXERCICES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6.2.1. Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of available tables \n",
    "tables = list(client.list_tables(dataset))\n",
    "list_of_tables = [table.table_id for table in tables] \n",
    "\n",
    "# Print your answer\n",
    "print(list_of_tables)\n",
    "\n",
    "# ['badges', 'comments', 'post_history', 'post_links', 'posts_answers', \n",
    "#  'posts_moderator_nomination', 'posts_orphaned_tag_wiki', \n",
    "#  'posts_privilege_wiki', 'posts_questions', 'posts_tag_wiki', \n",
    "#  'posts_tag_wiki_excerpt', 'posts_wiki_placeholder', 'stackoverflow_posts', \n",
    "#  'tags', 'users', 'votes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.6.2.2. Review relevant tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are interested in people who answer questions on a given topic, \n",
    "# the posts_answers table is a natural place to look. \n",
    "\n",
    "# Construct a reference to the \"posts_answers\" table\n",
    "answers_table_ref = dataset_ref.table(\"posts_answers\")\n",
    "\n",
    "# API request - fetch the table\n",
    "answers_table = client.get_table(answers_table_ref)\n",
    "\n",
    "# Preview the first five lines of the \"posts_answers\" table\n",
    "client.list_rows(answers_table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at posts_questions\n",
    "\n",
    "# Construct a reference to the \"posts_questions\" table\n",
    "questions_table_ref = dataset_ref.table(\"posts_questions\")\n",
    "\n",
    "# API request - fetch the table\n",
    "questions_table = client.get_table(questions_table_ref)\n",
    "\n",
    "# Preview the first five lines of the \"posts_questions\" table\n",
    "client.list_rows(questions_table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6.2.3. Selecting the right questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a query that selects the id, title and owner_user_id columns from \n",
    "# the posts_questions table.\n",
    "\n",
    "# Restrict the results to rows that contain the word \"bigquery\" in the tags\n",
    "# column.\n",
    "# Include rows where there is other text in addition to the word \"bigquery\"\n",
    "# (e.g., if a row has a tag \"bigquery-sql\", your results should include \n",
    "# that too).\n",
    "\n",
    "# Your code here\n",
    "questions_query =  \"\"\"\n",
    "                  SELECT id, title, owner_user_id\n",
    "                  FROM `bigquery-public-data.stackoverflow.posts_questions`\n",
    "                  WHERE tags LIKE '%bigquery%'\n",
    "                  \"\"\"\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 1 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "questions_query_job = client.query(questions_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "questions_results = questions_query_job.to_dataframe()\n",
    "\n",
    "# Preview results\n",
    "print(questions_results.head())\n",
    "\n",
    "#          id                                              title  owner_user_id\n",
    "# 0   4702789        How to Analyze and Query big chunks of data       435951.0\n",
    "# 1  63628724  Will the Firebase BigQuery export still work i...      7590610.0\n",
    "# 2  63758052  Scheduled query stopped writing to table in Bi...     13961038.0\n",
    "# 3  63716014  Inconsistent delay in firebase analytics event...       858350.0\n",
    "# 4  63604155       Dynamic Project names in BigQuery Procedures     10739327.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6.2.4. Your first join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a query that returns the id, body and owner_user_id columns from \n",
    "# the posts_answers table for answers to \"bigquery\"-related questions.\n",
    "\n",
    "# You should have one row in your results for each answer to a question \n",
    "# that has \"bigquery\" in the tags.\n",
    "# Remember you can get the tags for a question from the tags column in the \n",
    "# posts_questions table.\n",
    "\n",
    "# Your code here\n",
    "answers_query = \"\"\"\n",
    "                SELECT a.id, a.body, a.owner_user_id\n",
    "                FROM `bigquery-public-data.stackoverflow.posts_questions` AS q \n",
    "                INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                    ON q.id = a.parent_id\n",
    "                WHERE q.tags LIKE '%bigquery%'\n",
    "                \"\"\"\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 1 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "answers_query_job = client.query(answers_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "answers_results = answers_query_job.to_dataframe()\n",
    "\n",
    "# Preview results\n",
    "print(answers_results.head())\n",
    "\n",
    "#          id                                               body  owner_user_id\n",
    "# 0  61365135  <p>import os\\nfrom google.cloud.bigquery.clien...      6016731.0\n",
    "# 1  61366305  <p>As other answers were to hard for me I made...     10187000.0\n",
    "# 2  61389343  <p>I decided to poll with the command line gcl...      4355203.0\n",
    "# 3  61394597  <p>I did as SANN3 taught me, like a following:...      1332841.0\n",
    "# 4  61402047  <p>You can pass the schema explicitly and set ...      4334376.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6.2.5. Answer the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a new query that has a single row for each user who answered at \n",
    "# least one question with a tag that includes the string \"bigquery\". \n",
    "# Your results should have two columns:\n",
    "\n",
    "# user_id - contains the owner_user_id column from the posts_answers table\n",
    "# number_of_answers - contains the number of answers the user has written \n",
    "# to \"bigquery\"-related questions\n",
    "\n",
    "# Your code here\n",
    "bigquery_experts_query = \"\"\"\n",
    "                         SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n",
    "                         FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "                         INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                             ON q.id = a.parent_Id\n",
    "                         WHERE q.tags LIKE '%bigquery%'\n",
    "                         GROUP BY a.owner_user_id\n",
    "                         \"\"\"\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 1 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "bigquery_experts_query_job = client.query(bigquery_experts_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "bigquery_experts_results = bigquery_experts_query_job.to_dataframe()\n",
    "\n",
    "# Preview results\n",
    "print(bigquery_experts_results.head())\n",
    "\n",
    "#      user_id  number_of_answers\n",
    "# 0  4502697.0                  1\n",
    "# 1  2514521.0                  1\n",
    "# 2  7041871.0                  5\n",
    "# 3  2877278.0                260\n",
    "# 4  4821960.0                  1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6.2.6. Building a more generally useful service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How could you convert what you've done to a general function a website \n",
    "# could call on the backend to get experts on any topic?\n",
    "\n",
    "def expert_finder(topic, client):\n",
    "    '''\n",
    "    Returns a DataFrame with the user IDs who have written Stack Overflow answers on a topic.\n",
    "\n",
    "    Inputs:\n",
    "        topic: A string with the topic of interest\n",
    "        client: A Client object that specifies the connection to the Stack Overflow dataset\n",
    "\n",
    "    Outputs:\n",
    "        results: A DataFrame with columns for user_id and number_of_answers. Follows similar logic to bigquery_experts_results shown above.\n",
    "    '''\n",
    "    my_query = \"\"\"\n",
    "               SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n",
    "               FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "               INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                   ON q.id = a.parent_Id\n",
    "               WHERE q.tags like '%{topic}%'\n",
    "               GROUP BY a.owner_user_id\n",
    "               \"\"\"\n",
    "\n",
    "    # Set up the query (a real service would have good error handling for \n",
    "    # queries that scan too much data)\n",
    "    safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)      \n",
    "    my_query_job = client.query(my_query, job_config=safe_config)\n",
    "\n",
    "    # API request - run the query, and return a pandas DataFrame\n",
    "    results = my_query_job.to_dataframe()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
